{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ddf2940",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = \"D:/School/F22/ML+SL/project/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f71ffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import sys\n",
    "import argparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools\n",
    "from scipy import stats\n",
    "from sklearn.metrics import auc, accuracy_score, roc_curve, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import pylab as plot\n",
    "import pandas\n",
    "\n",
    "def get_feature_importances(data, shuffle, seed=None):\n",
    "    train_features = [f for f in data if f not in ['label']]\n",
    "    \n",
    "    # Shuffle target if required\n",
    "    y = data['label'].copy()\n",
    "    if shuffle:\n",
    "        y = data['label'].copy().sample(frac=1.0)\n",
    "\n",
    "    # Fit LightGBM in Random Forest mode (quicker than sklearn RandomForest)\n",
    "    dtrain = lgb.Dataset(data[train_features], y, free_raw_data=False, silent=True)\n",
    "    lgb_params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting_type': 'rf',\n",
    "        'learning_rate': .01,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'num_leaves': 12,\n",
    "        'max_depth': -1,\n",
    "        'n_jobs': -1,\n",
    "        'min_split_gain': .00001,\n",
    "        'reg_alpha': .00001,\n",
    "        'reg_lambda': .00001,\n",
    "        'metric': 'auc',\n",
    "        'bagging_freq': 1,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    # Fit the model\n",
    "    clf = lgb.train(params=lgb_params, train_set=dtrain, num_boost_round=200, categorical_feature=categorical_feats)\n",
    "\n",
    "    # Get feature importances\n",
    "    imp_df = pandas.DataFrame()\n",
    "    imp_df[\"feature\"] = list(train_features)\n",
    "    imp_df[\"importance_gain\"] = clf.feature_importance(importance_type='gain')\n",
    "    imp_df[\"importance_split\"] = clf.feature_importance(importance_type='split')\n",
    "    imp_df['trn_score'] = roc_auc_score(y, clf.predict(data[train_features]))\n",
    "    \n",
    "    return imp_df\n",
    "\n",
    "def display_distributions(actual_imp_df_, null_imp_df_, feature_):\n",
    "    plt.figure(figsize=(13, 6))\n",
    "    gs = gridspec.GridSpec(1, 1)\n",
    "    ax = plt.subplot(gs[0, 0])\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(8, 4)\n",
    "    params = {'legend.fontsize': 14, 'legend.handlelength': 2}\n",
    "    plot.rcParams.update(params)\n",
    "    null_imp_df_.loc[null_imp_df_['feature'] == feature_, 'importance_gain'].plot.kde(ax=ax, legend=True, label='Null distribution')\n",
    "    plt.axvline(actual_imp_df_.loc[actual_imp_df_['feature'] == feature_, 'importance_gain'].mean(), 0, np.max(null_imp_df_.loc[null_imp_df_['feature'] == feature_, 'importance_gain'].values), color='r', label='Observed importance')\n",
    "    ax.legend(loc=1)\n",
    "    plt.xlabel('Importance score', fontsize=14)\n",
    "    plt.ylabel('Density', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(feature_ + \"_importance_plot.svg\")\n",
    "    plt.savefig(feature_ + \"_importance_plot.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25f96375",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Wrong type(str) or unknown name(label) in categorical_feature",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m nb_runs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nb_runs):\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;66;03m# Get current run importances\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m     imp_df \u001b[38;5;241m=\u001b[39m \u001b[43mget_feature_importances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m     imp_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \n\u001b[0;32m     50\u001b[0m     null_imp_df \u001b[38;5;241m=\u001b[39m pandas\u001b[38;5;241m.\u001b[39mconcat([null_imp_df, imp_df], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36mget_feature_importances\u001b[1;34m(data, shuffle, seed)\u001b[0m\n\u001b[0;32m     32\u001b[0m lgb_params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboosting_type\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     47\u001b[0m }\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m clf \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlgb_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Get feature importances\u001b[39;00m\n\u001b[0;32m     53\u001b[0m imp_df \u001b[38;5;241m=\u001b[39m pandas\u001b[38;5;241m.\u001b[39mDataFrame()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:271\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 271\u001b[0m     booster \u001b[38;5;241m=\u001b[39m \u001b[43mBooster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[0;32m    273\u001b[0m         booster\u001b[38;5;241m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2605\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[1;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[0;32m   2598\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_network(\n\u001b[0;32m   2599\u001b[0m         machines\u001b[38;5;241m=\u001b[39mmachines,\n\u001b[0;32m   2600\u001b[0m         local_listen_port\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_listen_port\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   2601\u001b[0m         listen_time_out\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_out\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m120\u001b[39m),\n\u001b[0;32m   2602\u001b[0m         num_machines\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_machines\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   2603\u001b[0m     )\n\u001b[0;32m   2604\u001b[0m \u001b[38;5;66;03m# construct booster object\u001b[39;00m\n\u001b[1;32m-> 2605\u001b[0m \u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2606\u001b[0m \u001b[38;5;66;03m# copy the parameters from train_set\u001b[39;00m\n\u001b[0;32m   2607\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(train_set\u001b[38;5;241m.\u001b[39mget_params())\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1815\u001b[0m, in \u001b[0;36mDataset.construct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1812\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_init_score_by_predictor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predictor, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, used_indices)\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1814\u001b[0m     \u001b[38;5;66;03m# create train\u001b[39;00m\n\u001b[1;32m-> 1815\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1816\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1817\u001b[0m \u001b[43m                    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predictor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1818\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1819\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfree_raw_data:\n\u001b[0;32m   1821\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1509\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[0;32m   1507\u001b[0m         categorical_indices\u001b[38;5;241m.\u001b[39madd(name)\n\u001b[0;32m   1508\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1509\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong type(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(name)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) or unknown name(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) in categorical_feature\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m categorical_indices:\n\u001b[0;32m   1511\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cat_alias \u001b[38;5;129;01min\u001b[39;00m _ConfigAliases\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_feature\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mTypeError\u001b[0m: Wrong type(str) or unknown name(label) in categorical_feature"
     ]
    }
   ],
   "source": [
    "available_samples = [\"s1\"]\n",
    "cancer_type_list = ['bladder','breast','colon','kidney','leukemia',\n",
    "                    'liver','lung','ovarian','pancreatic']\n",
    "correlation_scores = []\n",
    "plotDistributions = True\n",
    "dataFolder = file_dir + 'training_set/'\n",
    "for cancer_type in cancer_type_list:\n",
    "    for sampleNumber in available_samples:\n",
    "        # Load dataset\n",
    "        data = pandas.read_csv(dataFolder + cancer_type + '_training_genes_set.csv', header=0, sep=\",\")\n",
    "        data.drop(\"gene\", axis=1, inplace=True)\n",
    "        data = data[data['label'] != 2]\n",
    "\n",
    "#             dataframePositive = data[data['label'] == 1]\n",
    "#             dataframeNegative = data[data['label'] == 0]\n",
    "#             positiveSize = dataframePositive.shape[0]\n",
    "#             negativeSize = dataframeNegative.shape[0]\n",
    "\n",
    "#             # Set them the same size\n",
    "#             if(positiveSize > negativeSize):\n",
    "#                 dataframePositive = dataframePositive.head(-(positiveSize-negativeSize))\n",
    "#             elif(negativeSize > positiveSize):\n",
    "#                 dataframeNegative = dataframeNegative.head(-(negativeSize-positiveSize))\n",
    "\n",
    "#             data = dataframePositive.copy()\n",
    "#             data = pd.concat([dataframePositive, dataframeNegative])\n",
    "\n",
    "        categorical_feats = [\n",
    "            f for f in data.columns if data[f].dtype == 'object'\n",
    "        ]\n",
    "\n",
    "        categorical_feats\n",
    "        for f_ in categorical_feats:\n",
    "            data[f_], _ = pandas.factorize(data[f_])\n",
    "            # Set feature type as categorical\n",
    "            data[f_] = data[f_].astype('category')\n",
    "\n",
    "        msk = np.random.rand(len(data)) < 0.7\n",
    "        traindf = data[msk].copy()\n",
    "        testdf = data[~msk].copy()\n",
    "        data = traindf\n",
    "\n",
    "        # Build Null Importances distribution\n",
    "        null_imp_df = pandas.DataFrame()\n",
    "        nb_runs = 100\n",
    "        for i in range(nb_runs):\n",
    "            # Get current run importances\n",
    "            imp_df = get_feature_importances(data=data, shuffle=True)\n",
    "            imp_df['run'] = i + 1 \n",
    "            null_imp_df = pandas.concat([null_imp_df, imp_df], axis=0)\n",
    "\n",
    "        # Build actual importances distribution\n",
    "        actual_imp_df = pandas.DataFrame()\n",
    "        imp_df = get_feature_importances(data=data, shuffle=False)\n",
    "        for i in range(nb_runs):\n",
    "            imp_df['run'] = i + 1 \n",
    "            # Concat the latest importances with the old ones\n",
    "            actual_imp_df = pandas.concat([actual_imp_df, imp_df], axis=0)\n",
    "\n",
    "        # display_distributions(actual_imp_df_=actual_imp_df, null_imp_df_=null_imp_df, feature_='mutation')\n",
    "        # display_distributions(actual_imp_df_=actual_imp_df, null_imp_df_=null_imp_df, feature_='expression')\n",
    "        # display_distributions(actual_imp_df_=actual_imp_df, null_imp_df_=null_imp_df, feature_='essentiality')\n",
    "\n",
    "        null_imp_df.to_csv('null_importances_distribution_rf.csv')\n",
    "        actual_imp_df.to_csv('actual_importances_ditribution_rf.csv')\n",
    "\n",
    "        # Z-score calculation\n",
    "        for _f in actual_imp_df['feature'].unique():\n",
    "            f_null_imps = null_imp_df.loc[null_imp_df['feature'] == _f, 'importance_gain'].values\n",
    "            f_act_imps = actual_imp_df.loc[actual_imp_df['feature'] == _f, 'importance_gain'].values\n",
    "            importancesDistribution = f_null_imps.tolist()\n",
    "            importancesDistribution.append(f_act_imps[0])\n",
    "            zScores = stats.zscore(importancesDistribution)\n",
    "            correlation_scores.append((_f, zScores[-1], sampleNumber))\n",
    "\n",
    "    corr_scores_df = pandas.DataFrame(correlation_scores, columns=['feature', 'z_score', 'sample_number'])\n",
    "    corr_scores_df = corr_scores_df.groupby(['feature', 'sample_number'], as_index=False).mean()\n",
    "    corr_scores_df = corr_scores_df.groupby(['feature'], as_index=False).mean()\n",
    "    corr_scores_df = corr_scores_df.sort_values('feature', ascending=True)\n",
    "    corr_scores_df.to_csv(\"output/feature_importance/\" + cancer_type + \"_feature_importance.csv\", encoding='utf-8', index=False)\n",
    "\n",
    "    # Plot the distributions?\n",
    "    if plotDistributions:\n",
    "        fig = plt.figure(figsize=(16, 16))\n",
    "        gs = gridspec.GridSpec(1, 1)\n",
    "\n",
    "        # Plot Gain importances\n",
    "        ax = plt.subplot(gs[0, 0])\n",
    "        sns.barplot(x='gain_score', y='feature', data=corr_scores_df.sort_values('gain_score', ascending=False), ax=ax)\n",
    "        ax.set_title('Feature scores wrt gain importances ', fontweight='bold', fontsize=14)\n",
    "\n",
    "        rects = ax.patches\n",
    "\n",
    "        # For each bar: Place a label\n",
    "        for index, rect in enumerate(rects):\n",
    "            # Get X and Y placement of label from rect.\n",
    "            x_value = rect.get_width()\n",
    "            y_value = rect.get_y() + rect.get_height() / 2\n",
    "\n",
    "            # Number of points between bar and label\n",
    "            space = 5\n",
    "\n",
    "            # Vertical alignment for positive values\n",
    "            ha = 'left'\n",
    "\n",
    "            # If value of bar is negative: Place label left of bar\n",
    "            if x_value < 0:\n",
    "                # Invert space to place label to the left\n",
    "                space *= -1\n",
    "                # Horizontally align label at right\n",
    "                ha = 'right'\n",
    "\n",
    "            # Use X value as label and format number with one decimal place\n",
    "            label = \"{:.1f}\".format(x_value)\n",
    "\n",
    "            # Create annotation\n",
    "            plt.annotate(\n",
    "                label,                      # Use `label` as label\n",
    "                (x_value, y_value),         # Place label at end of the bar\n",
    "                xytext=(space, 0),          # Horizontally shift label by `space`\n",
    "                textcoords=\"offset points\", # Interpret `xytext` as offset in points\n",
    "                va='center',                # Vertically center label\n",
    "                ha=ha)                      # Horizontally align label differently for\n",
    "                                            # positive and negative values.\n",
    "\n",
    "        plt.tight_layout()\n",
    "        fig.subplots_adjust(top=0.93)\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
